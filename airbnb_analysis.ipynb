{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Name: Ali Khatami\n",
    "# Course: DSC530-T301\n",
    "# Final Project: AirBNB price analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'paeto' from 'scipy.stats' (/Users/alikhatami/PycharmProjects/dsc530_final_project/bin/lib/python3.10/site-packages/scipy/stats/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[239], line 7\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mglob\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstats\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mstats\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstats\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m norm, expon, lognorm, paeto\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mthinkplot\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mthinkstats2\u001B[39;00m\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'paeto' from 'scipy.stats' (/Users/alikhatami/PycharmProjects/dsc530_final_project/bin/lib/python3.10/site-packages/scipy/stats/__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm, expon, lognorm, paeto\n",
    "import thinkplot\n",
    "import thinkstats2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1.  Your dataset\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all the csv files in the folder\n",
    "data_list = glob.glob('Airbnb Prices in Europe/*.csv')\n",
    "\n",
    "# Now we can use pandas to read all the csv files and combine them into one\n",
    "df = pd.concat(map(pd.read_csv, data_list))\n",
    "\n",
    "# Cross-Featuring the longitude and latitude\n",
    "df['lng-lat'] = df['lng'] * df['lat'] / 1000000\n",
    "\n",
    "# Drop the index column\n",
    "df.drop(['Unnamed: 0', 'rest_index_norm', 'attr_index_norm', 'room_private', 'room_shared', 'cleanliness_rating', 'lng', 'lat'], axis=1, inplace=True)\n",
    "\n",
    "# Check if there are any null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2.  A minimum of 5 variables in your dataset used during your analysis\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the first 5 rows of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming room_type to a dummy variable\n",
    "df = pd.get_dummies(df, columns=['room_type', 'host_is_superhost'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "3.  Include a histogram of each of the 5 variables\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the column names\n",
    "df.rename(columns={\n",
    "    'realSum': 'price', 'person_capacity': 'capacity', 'multi': '2_4_listings_host', 'biz': '4_plus_listings host', 'guest_satisfaction_overall': 'satisfaction_rating', 'dist': 'city_dist', 'attr_index': 'attractions_rating', 'rest_index': 'restaurants_rating'}, inplace=True)\n",
    "\n",
    "# Changing the data distributions\n",
    "df.hist(figsize=(20, 20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the correlation matrix and round to 4 decimals\n",
    "df.corr().round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating a heatmap visualization of the correlation matrix for the dataset using Seaborn and Matplotlib libraries. The first few lines set the style of the visualization to a white background. The correlation matrix is computed from the data and a mask is generated to hide the upper triangle of the matrix. Then, a custom colormap is generated and a heatmap is drawn using Seaborn. The resulting heatmap shows the correlations between the variables in the dataset, where red indicates positive correlation and blue indicates negative correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style of the visualization\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = df.corr()\n",
    "\n",
    "# Generate a mask the size of our covariance matrix\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the multi-collinear heatmap\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highly correlated variables in a dataset can cause issues in statistical analysis. When two variables are highly correlated, they contain redundant information, which can skew the results of analysis or models. Hence we remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing highly correlated variables\n",
    "df.drop(['attractions_rating', 'capacity', 'metro_dist'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this code is to visualize the distribution of the logarithmically transformed numerical variables to better understand where the median and mean fall and how the outliers are distributed. The logarithmic transformation is used to normalize the data and reduce the skewness of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting numerical variables\n",
    "num_vars = ['price', 'city_dist', 'satisfaction_rating', 'restaurants_rating', 'lng-lat', 'bedrooms']\n",
    "\n",
    "# Plotting the log transformation of all numerical variables\n",
    "np.log(df[num_vars] + 0.01).hist(figsize=(10, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "4.  Identify any outliers and explain the reasoning for them being outliers\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is used to identify outliers in the 'price' variable of a dataframe df using the z-score method and the threshold of 3 standard deviations away from the mean. Based on the results, we see price values over 1263 have been assigned as outliers as they are 3 standard deviations away from the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scores = stats.zscore(df['price'])\n",
    "outliers = df[abs(z_scores) > 3]\n",
    "print(f\"Minimum outlier price: {outliers['price'].min()}\")\n",
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "5.  How you believe they should be handled\n",
    "6.  Include the other descriptive characteristics about the variables: Mean, Mode, Spread, and Tails\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outliers are then removed from the dataframe and we get the new descriptive statistics of the dataframe that shows the mean and standard deviation of all the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers using the z-score method\n",
    "df = df.loc[abs(z_scores) < 3, :]\n",
    "\n",
    "# calculate summary statistics for the updated dataframe\n",
    "stats = df.describe()\n",
    "\n",
    "# calculate skewness for each column\n",
    "skewness = df.skew()\n",
    "skewness.name = 'skewness'\n",
    "\n",
    "# add the skewness row to the summary statistics dataframe\n",
    "summary_stats = stats.append(skewness)\n",
    "\n",
    "print(summary_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "7.  Compare two scenarios in your data using a PMF. Reminder, this isnâ€™t comparing two variables against each other â€“ it is the same variable, but a different scenario. Almost like a filter.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two scenarios to compare using the number of bedrooms\n",
    "scenario1 = df[df['room_type_Private room'] == 1]['price']\n",
    "scenario2 = df[df['room_type_Private room'] == 0]['price']\n",
    "\n",
    "# create PMFs for each scenario\n",
    "pmf1 = thinkstats2.Pmf(scenario1)\n",
    "pmf2 = thinkstats2.Pmf(scenario2)\n",
    "\n",
    "# plot PMFs using bar graphs using the bar function from thinkplot\n",
    "thinkplot.PrePlot(2)\n",
    "thinkplot.Hist(pmf1, align='right', width=0.5, color='green')\n",
    "thinkplot.Hist(pmf2, align='left', width=0.5, color='purple')\n",
    "thinkplot.Config(xlabel='Number of bedrooms', ylabel='PMF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two scenarios to compare using the number of bedrooms\n",
    "scenario1 = df[df['room_type_Private room'] == 1]['bedrooms']\n",
    "scenario2 = df[df['room_type_Private room'] == 0]['bedrooms']\n",
    "\n",
    "# create PMFs for each scenario\n",
    "pmf1 = thinkstats2.Pmf(scenario1)\n",
    "pmf2 = thinkstats2.Pmf(scenario2)\n",
    "\n",
    "# plot PMFs using bar graphs using the bar function from thinkplot\n",
    "thinkplot.PrePlot(2)\n",
    "thinkplot.Hist(pmf1, align='right', width=0.5, color='green')\n",
    "thinkplot.Hist(pmf2, align='left', width=0.5, color='purple')\n",
    "thinkplot.Config(xlabel='Number of bedrooms', ylabel='PMF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "8.  Create 1 CDF with one of your variables,\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = df['price'].value_counts().sort_index().cumsum()\n",
    "\n",
    "cdf = cdf / cdf.max()\n",
    "\n",
    "plt.plot(cdf.index, cdf)\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('CDF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# calculate mean and standard deviation of 'price' column\n",
    "mu, std = df['bedrooms'].mean(), df['bedrooms'].std()\n",
    "\n",
    "# create a normal distribution with the calculated mean and standard deviation\n",
    "dist = expon(mu, std)\n",
    "\n",
    "# create an x-axis range for the plot\n",
    "x = np.linspace(df['bedrooms'].min(), df['bedrooms'].max(), 100)\n",
    "\n",
    "# calculate the cdf values for the x range\n",
    "cdf = dist.cdf(x)\n",
    "\n",
    "# plot the cdf of the normal distribution\n",
    "plt.plot(x, cdf)\n",
    "\n",
    "# set the x and y labels of the plot\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('CDF')\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
