{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Name: Ali Khatami\n",
    "# Course: DSC530-T301\n",
    "# Final Project: AirBNB price analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm, expon, lognorm, pareto\n",
    "import thinkplot\n",
    "import thinkstats2\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1.  Your dataset\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all the csv files in the folder\n",
    "data_list = glob.glob('Airbnb Prices in Europe/*.csv')\n",
    "\n",
    "# Now we can use pandas to read all the csv files and combine them into one\n",
    "df = pd.concat(map(pd.read_csv, data_list))\n",
    "\n",
    "# Cross-Featuring the longitude and latitude\n",
    "df['lng-lat'] = df['lng'] * df['lat'] / 1000000\n",
    "\n",
    "# Drop the index column\n",
    "df.drop(['Unnamed: 0', 'rest_index_norm', 'attr_index_norm', 'room_private', 'room_shared', 'lng', 'lat'], axis=1, inplace=True)\n",
    "\n",
    "# Check if there are any null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2.  A minimum of 5 variables in your dataset used during your analysis\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the first 5 rows of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming room_type to a dummy variable\n",
    "df = pd.get_dummies(df, columns=['room_type', 'host_is_superhost'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "3.  Include a histogram of each of the 5 variables\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "outputs": [],
   "source": [
    "# Changing the column names\n",
    "df.rename(columns={\n",
    "    'realSum': 'price', 'person_capacity': 'capacity', 'multi': '2_4_listings_host', 'biz': '4_plus_listings host', 'guest_satisfaction_overall': 'satisfaction_rating', 'dist': 'city_dist', 'attr_index': 'attractions_rating', 'rest_index': 'restaurants_rating'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "outputs": [],
   "source": [
    "# Visualize the distribution of the prices\n",
    "plt.figure(figsize=(5, 3))\n",
    "df.price.hist()\n",
    "plt.xlabel(\"Price (£)\")\n",
    "plt.ylabel(\"Number of listings\")\n",
    "plt.title(\"Airbnb prices\", fontsize=16)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "outputs": [],
   "source": [
    "# Calculate the statistics of the prices\n",
    "df.price.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "outputs": [],
   "source": [
    "# Calculate the distribution of the prices\n",
    "bins = [0, 50, 100, 150, 200, 350, 500, 1000, 1500, 2500, 3000, 3500, int(df.price.max())]\n",
    "bin_counts = pd.cut(df.price, bins).value_counts()\n",
    "bin_percentages = bin_counts / df.shape[0] * 100\n",
    "hist_df = pd.DataFrame({'range': bin_percentages.index, '%': bin_percentages.values})\n",
    "hist_df = hist_df.sort_values('range').reset_index(drop=True)\n",
    "hist_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "outputs": [],
   "source": [
    "# Visualize the distribution of the prices up to £1500\n",
    "plt.figure(figsize=(5, 3))\n",
    "df.price.hist(bins=100, range=(0, 2000))\n",
    "plt.margins(x=0)\n",
    "plt.axvline(df.price.mean(), color='orange', linestyle='--')\n",
    "plt.axvline(df.price.median(), color='red', linestyle='--')\n",
    "plt.title(\"Airbnb prices up to £2000\", fontsize=16)\n",
    "plt.xlabel(\"Price (£)\")\n",
    "plt.ylabel(\"Number of listings\")\n",
    "plt.show()\n",
    "\n",
    "# Visualize the distribution of the prices from £2000 upwards\n",
    "plt.figure(figsize=(5, 3))\n",
    "df.price.hist(bins=100, range=(2000, max(df.price)))\n",
    "plt.margins(x=0)\n",
    "plt.axvline(df.price.mean(), color='orange', linestyle='--')\n",
    "plt.axvline(df.price.median(), color='red', linestyle='--')\n",
    "plt.title(\"Airbnb prices from £2000 upwards\", fontsize=16)\n",
    "plt.xlabel(\"Price (£)\")\n",
    "plt.ylabel(\"Number of listings\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the data distributions\n",
    "df.hist(figsize=(20, 20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the correlation matrix and round to 4 decimals\n",
    "df.corr().round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating a heatmap visualization of the correlation matrix for the dataset using Seaborn and Matplotlib libraries. The first few lines set the style of the visualization to a white background. The correlation matrix is computed from the data and a mask is generated to hide the upper triangle of the matrix. Then, a custom colormap is generated and a heatmap is drawn using Seaborn. The resulting heatmap shows the correlations between the variables in the dataset, where red indicates positive correlation and blue indicates negative correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style of the visualization\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = df.corr()\n",
    "\n",
    "# Generate a mask the size of our covariance matrix\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the multi-collinear heatmap\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highly correlated variables in a dataset can cause issues in statistical analysis. When two variables are highly correlated, they contain redundant information, which can skew the results of analysis or models. Hence we remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing highly correlated variables\n",
    "df.drop(['restaurants_rating', 'capacity', 'metro_dist'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this code is to visualize the distribution of the logarithmically transformed numerical variables to better understand where the median and mean fall and how the outliers are distributed. The logarithmic transformation is used to normalize the data and reduce the skewness of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting numerical variables\n",
    "num_vars = ['price', 'city_dist', 'satisfaction_rating', 'attractions_rating', 'lng-lat', 'bedrooms']\n",
    "\n",
    "# Logarithmic transformation of the numerical variables\n",
    "num_log = np.log(df[num_vars] + 0.01)\n",
    "\n",
    "# Plotting the log transformation of all numerical variables\n",
    "num_log.hist(figsize=(10, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "4.  Identify any outliers and explain the reasoning for them being outliers\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is used to identify outliers in the 'price' variable of a dataframe df using the z-score method and the threshold of 3 standard deviations away from the mean. Based on the results, we see price values over 1263 have been assigned as outliers as they are 3 standard deviations away from the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_outliers = df[abs(stats.zscore(df['price'])) > 3]\n",
    "print(f\"Minimum outlier price: {price_outliers['price'].min()}\")\n",
    "price_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "5.  How you believe they should be handled\n",
    "6.  Include the other descriptive characteristics about the variables: Mean, Mode, Spread, and Tails\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outliers are then removed from the dataframe and we get the new descriptive statistics of the dataframe that shows the mean and standard deviation of all the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the z-score for each value in the price column\n",
    "z_scores = stats.zscore(df['price'])\n",
    "\n",
    "# remove outliers using the z-score method\n",
    "df = df.loc[abs(z_scores) < 3, :]\n",
    "\n",
    "# calculate summary statistics for the updated dataframe\n",
    "stats = df.describe()\n",
    "\n",
    "# calculate skewness for each column\n",
    "skewness = df.skew()\n",
    "skewness.name = 'skewness'\n",
    "\n",
    "# add the skewness row to the summary statistics dataframe\n",
    "summary_stats = stats.append(skewness)\n",
    "\n",
    "# Add mode to the summary statistics dataframe\n",
    "summary_stats.loc['mode'] = df.mode().iloc[0]\n",
    "\n",
    "print(summary_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "7.  Compare two scenarios in your data using a PMF. Reminder, this isn’t comparing two variables against each other – it is the same variable, but a different scenario. Almost like a filter.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two scenarios to compare using the number of bedrooms\n",
    "scenario1 = df[df['room_type_Shared room'] == 1]['price']\n",
    "scenario2 = df[df['room_type_Shared room'] == 0]['price']\n",
    "\n",
    "# create PMFs for each scenario\n",
    "pmf1 = thinkstats2.Pmf(scenario1)\n",
    "pmf2 = thinkstats2.Pmf(scenario2)\n",
    "\n",
    "# plot PMFs using bar graphs using the bar function from thinkplot\n",
    "thinkplot.PrePlot(2)\n",
    "thinkplot.Hist(pmf1, align='right', width=5, color='green')\n",
    "thinkplot.Hist(pmf2, align='left', width=5, color='purple')\n",
    "thinkplot.Config(xlabel='Price', ylabel='PMF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two scenarios to compare using the number of bedrooms\n",
    "scenario1 = df[df['room_type_Private room'] == 1]['bedrooms']\n",
    "scenario2 = df[df['room_type_Private room'] == 0]['bedrooms']\n",
    "\n",
    "# create PMFs for each scenario\n",
    "pmf1 = thinkstats2.Pmf(scenario1)\n",
    "pmf2 = thinkstats2.Pmf(scenario2)\n",
    "\n",
    "# plot PMFs using bar graphs using the bar function from thinkplot\n",
    "thinkplot.PrePlot(2)\n",
    "thinkplot.Hist(pmf1, align='right', width=0.5, color='green')\n",
    "thinkplot.Hist(pmf2, align='left', width=0.5, color='purple')\n",
    "thinkplot.Config(xlabel='Number of bedrooms', ylabel='PMF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "8.  Create 1 CDF with one of your variables,\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = df['price'].value_counts().sort_index().cumsum()\n",
    "\n",
    "cdf = cdf / cdf.max()\n",
    "\n",
    "plt.plot(cdf.index, cdf)\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('CDF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "9.  Plot 1 analytical distribution\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "outputs": [],
   "source": [
    "# calculate mean and standard deviation of 'price' column\n",
    "mu, std = df['price'].mean(), df['price'].std()\n",
    "\n",
    "# create a normal distribution with the calculated mean and standard deviation\n",
    "dist = norm(mu, std)\n",
    "\n",
    "# create an x-axis range for the plot\n",
    "x = np.linspace(df['price'].min(), df['price'].max(), 100)\n",
    "\n",
    "# calculate the cdf values for the x range\n",
    "cdf = dist.cdf(x)\n",
    "\n",
    "# plot the cdf of the normal distribution\n",
    "plt.plot(x, cdf)\n",
    "\n",
    "# set the x and y labels of the plot\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('CDF')\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "10. Create two scatter plots comparing two variables and provide your analysis on correlation and causation. Remember, covariance, Pearson’s correlation, and Non-Linear Relationships should also be considered during your analysis\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "outputs": [],
   "source": [
    "# Create scatter plot of price vs. number of bedrooms\n",
    "sns.lmplot(x='attractions_rating', y='price', data=df,\n",
    "           line_kws={'color': 'blue'}, ci=None, scatter_kws={'alpha':0.5})\n",
    "plt.title('Scatter plot of price vs. attractions rating')\n",
    "plt.show()\n",
    "\n",
    "# Create scatter plot of price vs. city distance\n",
    "sns.lmplot(x='city_dist', y='price', data=df,\n",
    "           line_kws={'color': 'blue'}, ci=None, scatter_kws={'alpha':0.5})\n",
    "plt.title('Scatter plot of price vs. distance to the city center')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "outputs": [],
   "source": [
    "# Calculate the covariance between \"price\" and \"number of bedrooms\"\n",
    "covariance = df['satisfaction_rating'].cov(df['city_dist'])\n",
    "\n",
    "# Calculate the Pearson's correlation coefficient between \"price\" and \"number of bedrooms\"\n",
    "corr_coeff = df['satisfaction_rating'].corr(df['city_dist'])\n",
    "\n",
    "print('Covariance:', covariance)\n",
    "print('Pearson\\'s correlation coefficient:', corr_coeff)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "11. Conduct a test on your hypothesis using one of the methods\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "null hypothesis:  listings with different room types have the same mean price.\n",
    "alternative hypothesis:  listings with room type of private room have a higher mean price than listings with room type of shared room.\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "outputs": [],
   "source": [
    "class MeanPriceDiffTest(thinkstats2.HypothesisTest):\n",
    "    def TestStatistic(self, data):\n",
    "        group1, group2 = data\n",
    "        test_stat = abs(np.mean(group1) - np.mean(group2))\n",
    "        return test_stat\n",
    "\n",
    "    def MakeModel(self):\n",
    "        group1, group2 = self.data\n",
    "        self.n, self.m = len(group1), len(group2)\n",
    "        self.pool = np.hstack((group1, group2))\n",
    "\n",
    "    def RunModel(self):\n",
    "        np.random.shuffle(self.pool)\n",
    "        data = self.pool[:self.n], self.pool[self.n:]\n",
    "        return data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "outputs": [],
   "source": [
    "# create two groups to compare\n",
    "group1 = df[df['room_type_Private room'] == 1]['price']\n",
    "group2 = df[df['room_type_Private room'] == 0]['price']\n",
    "\n",
    "# run the hypothesis test\n",
    "ht = MeanPriceDiffTest((group1, group2))\n",
    "\n",
    "# p-value\n",
    "pvalue = ht.PValue()\n",
    "\n",
    "# t-statistic"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "12. For this project, conduct a regression analysis on either one dependent and one explanatory variable, or multiple explanatory variables\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "outputs": [],
   "source": [
    "def regression_analysis(X, y, model, degree):\n",
    "    # Get the polynomial features of the explanatory variables\n",
    "    X = PolynomialFeatures(degree=degree, include_bias=False).fit_transform(X)\n",
    "\n",
    "    # fit the model to the data\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # print the R^2 value\n",
    "    print('R^2: ', r2_score(y, model.predict(X)))\n",
    "    print('MSE: ', mean_squared_error(y, model.predict(X)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "outputs": [],
   "source": [
    "# Choose the dependent variable\n",
    "y = df['price']\n",
    "\n",
    "# Choose the explanatory variables\n",
    "X = df.drop('price', axis=1)\n",
    "\n",
    "# Create a linear regression model\n",
    "reg_1def = regression_analysis(X, y, LinearRegression(), 1)\n",
    "reg_1def"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "outputs": [],
   "source": [
    "# 2 Degree Polynomial Regression\n",
    "reg_2def = regression_analysis(X, y, LinearRegression(), 2)\n",
    "reg_2def"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "outputs": [],
   "source": [
    "# 3 Degree Polynomial Regression\n",
    "reg_3def = regression_analysis(X, y, LinearRegression(), 3)\n",
    "reg_3def"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "outputs": [],
   "source": [
    "# 4 Degree Polynomial Regression\n",
    "reg_4def = regression_analysis(X, y, LinearRegression(), 4)\n",
    "reg_4def"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Use statsmodels to get p-values\n",
    "X_poly_sm = sm.add_constant(X)\n",
    "model = sm.OLS(y, X_poly_sm)\n",
    "results = model.fit()\n",
    "p_values = results.pvalues[1:]\n",
    "\n",
    "# sort the p-values from lowest to highest\n",
    "p_values.sort_values(ascending=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
